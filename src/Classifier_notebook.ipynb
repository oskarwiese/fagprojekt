{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import GPyOpt\n",
    "s = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "No GPU available.\n"
     ]
    }
   ],
   "source": [
    "#data = pd.read_csv(\"/home/oskar/Desktop/fagprojekt/compas/compas-scores-raw.csv\")\n",
    "url = \"https://raw.githubusercontent.com/oskarwiese/fagprojekt/master/compas/compas-scores-raw.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/oskarwiese/fagprojekt/master/compas_propublica/compas-scores-two-years.csv\"\n",
    "new_data = pd.read_csv(url)\n",
    "# Til at se p√• dataen \n",
    "#print(data.head)\n",
    "#print(data.columns)\n",
    "\n",
    "# Check if there are any missing values\n",
    "print(np.count_nonzero(data[\"IsDeleted\"] == 1))\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"Running GPU.\") if use_cuda else print(\"No GPU available.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_plot():\n",
    "    sb.countplot(x = \"score_text\", hue = \"race\", data = new_data)\n",
    "    plt.show()\n",
    "\n",
    "    sb.countplot(x = \"two_year_recid\", hue = \"race\", data = new_data)\n",
    "    plt.show()\n",
    "    sb.countplot(x = \"is_recid\", hue = \"race\", data = new_data)\n",
    "    plt.show()\n",
    "    sb.countplot(x = \"is_violent_recid\", hue = \"race\", data = new_data)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots():\n",
    "    # Show distribution of different ethnicities and sexes\n",
    "    chart = sb.countplot(x = \"Ethnic_Code_Text\", data = data)\n",
    "    chart.set_xticklabels(chart.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "    chart.set(xlabel='Ethnicity', ylabel='Count')\n",
    "    plt.show()\n",
    "    \n",
    "    chart = sb.countplot(x = \"Sex_Code_Text\", data = data)\n",
    "    chart.set(xlabel='Sex', ylabel='Count')\n",
    "    plt.show()\n",
    "    \n",
    "    sb.countplot(x = \"Language\", data = data)\n",
    "    plt.show()\n",
    "    \n",
    "    # Showing the distribution of the raw and decile values\n",
    "    plt.xlabel(\"Raw value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Visualization of the values\")\n",
    "    plt.hist(data[\"RawScore\"])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.xlabel(\"Decile value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Visualization of the decile values\")\n",
    "    plt.hist(data[\"DecileScore\"])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    #sb.countplot(x = \"RawScore\", hue = \"Ethnic_Code_Text\", data = data)\n",
    "    #plt.show()\n",
    "    \n",
    "    # Indication that some black people might get higher sentences that white people\n",
    "    sb.countplot(x = \"DecileScore\", hue = \"Ethnic_Code_Text\", data = data)\n",
    "    plt.show()\n",
    "    \n",
    "    sb.countplot(x = \"ScoreText\", hue = \"Ethnic_Code_Text\", data = data)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = [\"Agency_Text\", \"Sex_Code_Text\", \"Ethnic_Code_Text\", \"ScaleSet_ID\", \"AssessmentReason\", \"Language\", \"LegalStatus\", \"CustodyStatus\", \"MaritalStatus\", \"RecSupervisionLevel\"]\n",
    "new_categoricals = [\"c_charge_degree\", \"race\", \"age_cat\", \"sex\", \"is_recid\", \"is_violent_recid\", \"c_charge_degree\"] # \"r_charge_degree\"    \"two_year_recid\"\n",
    "# Changing date of birth into age,as this should work better in a neural network\n",
    "new_numericals = [\"age\", \"priors_count\", \"juv_fel_count\", \"juv_misd_count\"] # \"days_b_screening_arrest\"\n",
    "\n",
    "if s == 1:\n",
    "    ages = [None] * len(data[\"DateOfBirth\"])\n",
    "    for i in range(len(data[\"DateOfBirth\"])):\n",
    "        ages[i] = 20 +(100 - int(data[\"DateOfBirth\"][i].split(\"/\")[2]))\n",
    "    data[\"DateOfBirth\"] = ages\n",
    "    numericals = [\"DateOfBirth\"]\n",
    "    s+=1\n",
    "else:\n",
    "    pass\n",
    "\n",
    "outputs = [\"ScoreText\"]\n",
    "new_outputs = [\"score_text\"]\n",
    "\n",
    "data = data.dropna(axis = 0, how = 'any')\n",
    "data[outputs] = data[outputs].replace('Low',0)\n",
    "data[outputs] = data[outputs].replace('Medium',1)\n",
    "data[outputs] = data[outputs].replace('High',1)\n",
    "data[outputs] = data[outputs].astype(\"category\")\n",
    "\n",
    "\n",
    "new_data[new_outputs] = new_data[new_outputs].replace('Low',0)\n",
    "new_data[new_outputs] = new_data[new_outputs].replace('Medium',1)\n",
    "new_data[new_outputs] = new_data[new_outputs].replace('High',1)\n",
    "new_data[new_outputs] = new_data[new_outputs].astype(\"category\")\n",
    "\n",
    "\n",
    "for category in categoricals:\n",
    "    data[category] = data[category].astype(\"category\")\n",
    "    \n",
    "for new_category in new_categoricals:\n",
    "    new_data[new_category] = new_data[new_category].astype(\"category\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6538, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2051, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0769, 0.1053, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0769, 0.0526, 0.0000, 0.0000],\n",
       "         [0.4359, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1410, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.3934, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1967, 0.0263, 0.0000, 0.0000],\n",
       "         [0.2459, 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.6393, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2459, 0.0789, 0.0000, 0.0000],\n",
       "         [0.0820, 0.0526, 0.0000, 0.0000]]))"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Preparing data for pytorch\n",
    "Xcat = []\n",
    "for i in range(len(categoricals)):\n",
    "    Xcat.append(data[categoricals[i]].cat.codes.values)\n",
    "Xcat = torch.tensor(Xcat , dtype = torch.int64).T\n",
    "\n",
    "\n",
    "new_Xcat = []\n",
    "for i in range(len(new_categoricals)):\n",
    "    new_Xcat.append(new_data[new_categoricals[i]].cat.codes.values)\n",
    "new_Xcat = torch.tensor(new_Xcat , dtype = torch.int64).T\n",
    "\n",
    "#Converting the numerical values to a tensor\n",
    "Xnum = np.stack([data[col].values for col in numericals], 1)\n",
    "Xnum = torch.tensor(Xnum, dtype=torch.float)\n",
    "\n",
    "\n",
    "new_Xnum = np.stack([new_data[col].values for col in new_numericals], 1)\n",
    "new_Xnum = torch.tensor(new_Xnum, dtype=torch.float)\n",
    "\n",
    "# Converting the output to tensor\n",
    "y = torch.tensor(data[outputs].values).flatten()\n",
    "new_y = torch.tensor(new_data[new_outputs].values).flatten()\n",
    "\n",
    "# Calculation of embedding sizes for the categorical values in the format (unique categorical values, embedding size (dimension of encoding))\n",
    "categorical_column_sizes = [len(data[column].cat.categories) for column in categoricals]\n",
    "categorical_embedding_sizes = [(col_size, min(50, (col_size+1)//2)) for col_size in categorical_column_sizes]\n",
    "\n",
    "\n",
    "new_categorical_column_sizes = [len(new_data[column].cat.categories) for column in new_categoricals]\n",
    "new_categorical_embedding_sizes = [(col_size, min(50, (col_size+1)//2)) for col_size in new_categorical_column_sizes]\n",
    "\n",
    "# Train-test split\n",
    "totalnumber = len(Xnum)\n",
    "testnumber = int(totalnumber * 0.2)\n",
    "\n",
    "\n",
    "new_totalnumber = len(new_Xnum)\n",
    "new_testnumber = int(new_totalnumber * 0.2)\n",
    "\n",
    "Xcattrain = Xcat[:totalnumber - testnumber]\n",
    "Xcattest = Xcat[totalnumber - testnumber:totalnumber]\n",
    "Xnumtrain = Xnum[:totalnumber - testnumber]\n",
    "Xnumtest = Xnum[totalnumber - testnumber:totalnumber]\n",
    "ytrain = y[:totalnumber - testnumber]\n",
    "ytest = y[totalnumber - testnumber:totalnumber]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "new_Xcattrain = new_Xcat[:new_totalnumber - new_testnumber]\n",
    "new_Xcattest = new_Xcat[new_totalnumber - new_testnumber:new_totalnumber]\n",
    "new_Xnumtrain = new_Xnum[:new_totalnumber - new_testnumber]\n",
    "new_Xnumtest = new_Xnum[new_totalnumber - new_testnumber:new_totalnumber]\n",
    "new_ytrain = new_y[:new_totalnumber - new_testnumber]\n",
    "new_ytest = new_y[new_totalnumber - new_testnumber:new_totalnumber]\n",
    "\n",
    "# Make sure that we dont validate on training data to compare if the algorithm is biased\n",
    "df = df[new_totalnumber - new_testnumber:new_totalnumber]\n",
    "black_data = df[df[\"race\"]==\"African-American\"]\n",
    "white_data = df[df[\"race\"]==\"Caucasian\"]\n",
    "\n",
    "def normalize(type):\n",
    "    global new_ytain, new_ytest\n",
    "    if type == \"minmax\":\n",
    "        for i in range(new_Xnumtrain.size()[1]):\n",
    "            new_Xnumtrain[:,i] = (new_Xnumtrain[:,i]-new_Xnumtrain[:,i].min()) / (new_Xnumtrain[:,i].max()-new_Xnumtrain[:,i].min())\n",
    "            new_Xnumtest[:,i] = (new_Xnumtest[:,i]-new_Xnumtest[:,i].min()) / (new_Xnumtest[:,i].max()-new_Xnumtest[:,i].min())\n",
    "        return new_Xnumtrain, new_Xnumtest\n",
    "    elif type == \"zscore\":\n",
    "        for i in range(new_Xnumtrain.size()[1]):\n",
    "            new_Xnumtrain[:,i] = (new_Xnumtrain[:,i]-new_Xnumtrain[:,i].mean()) / (new_Xnumtrain[:,i].std())\n",
    "            new_Xnumtest[:,i] = (new_Xnumtest[:,i]-new_Xnumtest[:,i].mean()) / (new_Xnumtest[:,i].std())\n",
    "        return new_Xnumtrain, new_Xnumtest\n",
    "    elif type == \"none\":\n",
    "        return new_Xnumtrain, new_Xnumtest\n",
    "    else:\n",
    "        raise ValueError(\"Please choose a correct normalization type\")\n",
    "        \n",
    "normalize(\"zscore\") ;\n",
    "\n",
    "#new_Xnumtrain = torch.tensor(np.vstack([(new_Xnumtrain[:,i]-new_Xnumtrain[:,i].min()) / (new_Xnumtrain[:,i].max()-new_Xnumtrain[:,i].min()) for i in range(new_Xnumtrain.size()[1]) if \"Tue elsker det her\"])).view(-1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size, num_numerical_cols, output_size, layers, p=0.4):\n",
    "        super().__init__()\n",
    "        self.all_embeddings = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in embedding_size])\n",
    "        self.embedding_dropout = nn.Dropout(p)\n",
    "        self.batch_norm_num = nn.BatchNorm1d(num_numerical_cols)\n",
    "\n",
    "        all_layers = []\n",
    "        num_categorical_cols = sum((nf for ni, nf in embedding_size))\n",
    "        input_size = num_categorical_cols + num_numerical_cols\n",
    "\n",
    "        for i in layers:\n",
    "            all_layers.append(nn.Linear(input_size, i))\n",
    "            all_layers.append(nn.ReLU(inplace=True))\n",
    "            all_layers.append(nn.BatchNorm1d(i))\n",
    "            all_layers.append(nn.Dropout(p))\n",
    "            input_size = i\n",
    "\n",
    "        all_layers.append(nn.Linear(layers[-1], output_size))\n",
    "\n",
    "        self.layers = nn.Sequential(*all_layers)\n",
    "\n",
    "    def forward(self, x_categorical, x_numerical):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.all_embeddings):\n",
    "            embeddings.append(e(x_categorical[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.embedding_dropout(x)\n",
    "\n",
    "        x_numerical = self.batch_norm_num(x_numerical)\n",
    "        x = torch.cat([x, x_numerical], 1)\n",
    "        x = self.layers(x)\n",
    "        return nn.functional.softmax(x, dim = -1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model on old data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (all_embeddings): ModuleList(\n",
      "    (0): Embedding(4, 2)\n",
      "    (1): Embedding(2, 1)\n",
      "    (2): Embedding(9, 5)\n",
      "    (3): Embedding(2, 1)\n",
      "    (4): Embedding(1, 1)\n",
      "    (5): Embedding(2, 1)\n",
      "    (6): Embedding(5, 3)\n",
      "    (7): Embedding(6, 3)\n",
      "    (8): Embedding(7, 4)\n",
      "    (9): Embedding(4, 2)\n",
      "  )\n",
      "  (embedding_dropout): Dropout(p=0.6, inplace=False)\n",
      "  (batch_norm_num): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=24, out_features=10, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.6, inplace=False)\n",
      "    (4): Linear(in_features=10, out_features=20, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.6, inplace=False)\n",
      "    (8): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): Dropout(p=0.6, inplace=False)\n",
      "    (12): Linear(in_features=20, out_features=10, bias=True)\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (15): Dropout(p=0.6, inplace=False)\n",
      "    (16): Linear(in_features=10, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define and show the model\n",
    "#model = Model(categorical_embedding_sizes, 1, 2, [8,16,32,64,128], p=0.6)\n",
    "model = Model(categorical_embedding_sizes, 1, 2, [10,20,20,10], p=0.6)\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimization\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001 , weight_decay = 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1 loss: 0.75206149\n",
      "epoch:  26 loss: 0.72992122\n",
      "epoch:  51 loss: 0.71563697\n",
      "epoch:  76 loss: 0.69822705\n",
      "epoch: 100 loss: 0.6815894246\n",
      "[[1999   82]\n",
      " [ 786  260]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.96      0.82      2081\n",
      "           1       0.76      0.25      0.37      1046\n",
      "\n",
      "   micro avg       0.72      0.72      0.72      3127\n",
      "   macro avg       0.74      0.60      0.60      3127\n",
      "weighted avg       0.73      0.72      0.67      3127\n",
      "\n",
      "0.7224176527022705\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 100\n",
    "aggregated_losses = []\n",
    "\n",
    "# Initialize lists for training and validation\n",
    "train_iter = []\n",
    "train_loss, train_accs = [], []\n",
    "valid_iter = []\n",
    "valid_loss, valid_accs = [], []\n",
    "\n",
    "model.train()\n",
    "for i in range(epochs):\n",
    "    i += 1\n",
    "    y_pred = model(Xcattrain, Xnumtrain)\n",
    "    single_loss = loss_function(y_pred, ytrain)\n",
    "    aggregated_losses.append(single_loss)\n",
    "    \n",
    "    if i % 25 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    single_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')\n",
    "    \n",
    "\n",
    "\n",
    "# Plot the loss over epocs\n",
    "plt.plot(range(epochs), aggregated_losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch');\n",
    "\n",
    "\n",
    "# Predict on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_val = model(Xcattest, Xnumtest)\n",
    "    loss = loss_function(y_val, ytest)\n",
    "\n",
    "\n",
    "y_val = np.argmax(y_val, axis=1)\n",
    "\n",
    "\n",
    "print(confusion_matrix(ytest,y_val))\n",
    "print(classification_report(ytest,y_val))\n",
    "print(accuracy_score(ytest, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (all_embeddings): ModuleList(\n",
      "    (0): Embedding(2, 1)\n",
      "    (1): Embedding(6, 3)\n",
      "    (2): Embedding(3, 2)\n",
      "    (3): Embedding(2, 1)\n",
      "    (4): Embedding(2, 1)\n",
      "    (5): Embedding(2, 1)\n",
      "    (6): Embedding(2, 1)\n",
      "  )\n",
      "  (embedding_dropout): Dropout(p=0.5, inplace=False)\n",
      "  (batch_norm_num): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=14, out_features=16, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=16, out_features=32, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.5, inplace=False)\n",
      "    (8): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): Dropout(p=0.5, inplace=False)\n",
      "    (12): Linear(in_features=64, out_features=128, bias=True)\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (15): Dropout(p=0.5, inplace=False)\n",
      "    (16): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): Dropout(p=0.5, inplace=False)\n",
      "    (20): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define and show the model\n",
    "model = Model(new_categorical_embedding_sizes, 4, 2, [16,32,64,128,64], p=0.5)\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimization\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay = 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1 loss: 0.71623278\n",
      "epoch:  26 loss: 0.67541564\n",
      "epoch:  51 loss: 0.64809108\n",
      "epoch:  76 loss: 0.62171721\n",
      "epoch: 101 loss: 0.59781498\n",
      "epoch: 126 loss: 0.58341163\n",
      "epoch: 151 loss: 0.57655054\n",
      "epoch: 176 loss: 0.56717110\n",
      "epoch: 201 loss: 0.56028104\n",
      "epoch: 226 loss: 0.55894518\n",
      "epoch: 251 loss: 0.55859530\n",
      "epoch: 276 loss: 0.55566078\n",
      "epoch: 300 loss: 0.5533775091\n",
      "[[613 157]\n",
      " [205 467]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77       770\n",
      "           1       0.75      0.69      0.72       672\n",
      "\n",
      "    accuracy                           0.75      1442\n",
      "   macro avg       0.75      0.75      0.75      1442\n",
      "weighted avg       0.75      0.75      0.75      1442\n",
      "\n",
      "0.7489597780859917\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 100\n",
    "aggregated_losses = []\n",
    "\n",
    "# Initialize lists for training and validation\n",
    "train_iter = []\n",
    "train_loss, train_accs = [], []\n",
    "valid_iter = []\n",
    "valid_loss, valid_accs = [], []\n",
    "\n",
    "model.train()\n",
    "for i in range(epochs):\n",
    "    i += 1\n",
    "    y_pred = model(new_Xcattrain, new_Xnumtrain)\n",
    "    single_loss = loss_function(y_pred, new_ytrain)\n",
    "    aggregated_losses.append(single_loss)\n",
    "    \n",
    "    if i % 25 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    single_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')\n",
    "    \n",
    "\n",
    "\n",
    "# Plot the loss over epocs\n",
    "plt.plot(range(epochs), aggregated_losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch');\n",
    "\n",
    "\n",
    "# Predict on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_val = model(new_Xcattest, new_Xnumtest)\n",
    "    loss = loss_function(y_val, new_ytest)\n",
    "\n",
    "\n",
    "y_val = np.argmax(y_val, axis=1)\n",
    "\n",
    "\n",
    "print(confusion_matrix(new_ytest,y_val))\n",
    "print(classification_report(new_ytest,y_val))\n",
    "print(accuracy_score(new_ytest, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep black and white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confussion matrix for the white:\n",
      "[[221  76]\n",
      " [ 58 120]]\n",
      "[[0.74410774 0.42696629]\n",
      " [0.1952862  0.6741573 ]]\n",
      "\n",
      "Confussion matrix for the black:\n",
      "[[279  70]\n",
      " [171 224]]\n",
      "[[0.79942693 0.17721519]\n",
      " [0.48997135 0.56708861]]\n"
     ]
    }
   ],
   "source": [
    "new_categoricals = [\"c_charge_degree\", \"race\", \"age_cat\", \"sex\", \"is_recid\", \"is_violent_recid\", \"c_charge_degree\"] # \"r_charge_degree\"    \"two_year_recid\"\n",
    "new_numericals = [\"age\", \"priors_count\", \"juv_fel_count\", \"juv_misd_count\"]\n",
    "    \n",
    "for new_category in new_categoricals:\n",
    "    white_data[new_category] = white_data[new_category].astype(\"category\")\n",
    "    black_data[new_category] = black_data[new_category].astype(\"category\")\n",
    "\n",
    "Xcat_white, Xcat_black = [] ,[]\n",
    "for i in range(len(new_categoricals)):\n",
    "    Xcat_white.append(white_data[new_categoricals[i]].cat.codes.values)\n",
    "    Xcat_black.append(black_data[new_categoricals[i]].cat.codes.values)\n",
    "Xcat_white = torch.tensor(Xcat_white , dtype = torch.int64).T\n",
    "Xcat_black = torch.tensor(Xcat_black , dtype = torch.int64).T \n",
    "\n",
    "Xnum_white = np.stack([white_data[col].values for col in new_numericals], 1)\n",
    "Xnum_white = torch.tensor(Xnum_white, dtype=torch.float)\n",
    "Xnum_black = np.stack([black_data[col].values for col in new_numericals], 1)\n",
    "Xnum_black = torch.tensor(Xnum_black, dtype=torch.float)\n",
    "\n",
    "\n",
    "def normalize(train,test, type):\n",
    "    global new_ytain, new_ytest\n",
    "    if type == \"minmax\":\n",
    "        for i in range(train.size()[1]):\n",
    "            train[:,i] = (train[:,i]-train[:,i].min()) / (train[:,i].max()-train[:,i].min())\n",
    "            test[:,i] = (test[:,i]-test[:,i].min()) / (test[:,i].max()-test[:,i].min())\n",
    "        return train , test\n",
    "    elif type == \"zscore\":\n",
    "        for i in range(train.size()[1]):\n",
    "            train[:,i] = (train[:,i]-train[:,i].mean()) / (train[:,i].std())\n",
    "            test[:,i] = (test[:,i]-test[:,i].mean()) / (test[:,i].std())\n",
    "        return train, test\n",
    "    else:\n",
    "        raise ValueError(\"Please choose a correct normalization type\")\n",
    "        \n",
    "normalize(Xnum_white, Xnum_black, \"zscore\")\n",
    "model.eval()\n",
    "y_val_white = model(Xcat_white, Xnum_white)\n",
    "y_val_white = np.argmax(y_val_white.detach().numpy(), axis = 1)\n",
    "y_val_black = model(Xcat_black, Xnum_black)\n",
    "y_val_black = np.argmax(y_val_black.detach().numpy(), axis = 1)\n",
    "\n",
    "# Ground truth of recidivism from dataset\n",
    "y_white = torch.tensor(white_data[\"two_year_recid\"].values).flatten()\n",
    "y_black = torch.tensor(black_data[\"two_year_recid\"].values).flatten()\n",
    "\n",
    "print(\"Confussion matrix for the white:\")\n",
    "conf_white = confusion_matrix( y_white, y_val_white)\n",
    "print(conf_white)\n",
    "print(conf_white / conf_white.astype(np.float).sum(axis=1))\n",
    "print()\n",
    "print(\"Confussion matrix for the black:\")\n",
    "conf_black = confusion_matrix( y_black, y_val_black)\n",
    "print(conf_black)\n",
    "print(conf_black / conf_black.astype(np.float).sum(axis=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the old data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times low scoretext is predicted:  1954\n",
      "Times medium scoretext is predicted:  534\n",
      "Times high scoretext is predicted:  639\n",
      "Accuracy of the random forest model:  0.7547169811320755\n"
     ]
    }
   ],
   "source": [
    "# Define the model and fit it to the data\n",
    "forestModel = RandomForestClassifier(n_estimators = 53, max_depth = 14, max_features = \"log2\", criterion = \"entropy\")\n",
    "forestModel.fit(Xcattrain, ytrain)\n",
    "\n",
    "# Predict on the test set\n",
    "forestPreds = forestModel.predict(Xcattest)\n",
    "forestProbs = forestModel.predict_proba(Xcattest)[:, 1]\n",
    "\n",
    "print(\"Times low scoretext is predicted: \", len(forestPreds[forestPreds == 0]))\n",
    "print(\"Times medium scoretext is predicted: \", len(forestPreds[forestPreds == 1]))\n",
    "print(\"Times high scoretext is predicted: \", len(forestPreds[forestPreds == 2]))\n",
    "\n",
    "print(\"Accuracy of the random forest model: \", len(forestPreds[torch.tensor(forestPreds, dtype = torch.int64) == ytest]) / len(forestPreds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted no recidivism:  803\n",
      "Predicted recidivism:  639\n",
      "Accuracy of the random forest model:  0.6692094313453537\n"
     ]
    }
   ],
   "source": [
    "# Define the model and fit it to the data\n",
    "forestModel = RandomForestClassifier(n_estimators = 53, max_depth = 14, max_features = \"log2\", criterion = \"entropy\")\n",
    "forestModel.fit(new_Xcattrain, new_ytrain)\n",
    "\n",
    "# Predict on the test set\n",
    "forestPreds = forestModel.predict(new_Xcattest)\n",
    "\n",
    "forestProbs = forestModel.predict_proba(new_Xcattest)[:, 1]\n",
    "\n",
    "print(\"Predicted no recidivism: \", len(forestPreds[forestPreds == 0]))\n",
    "print(\"Predicted recidivism: \", len(forestPreds[forestPreds == 1]))\n",
    "\n",
    "print(\"Accuracy of the random forest model: \", len(forestPreds[torch.tensor(forestPreds, dtype = torch.int64) == new_ytest]) / len(forestPreds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baysian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[290.   2.   0.   1.]]\n",
      "[[170.  73.   0.   1.]]\n",
      "[[160.  40.   1.   1.]]\n",
      "[[27. 62.  0.  0.]]\n",
      "[[55. 59.  1.  0.]]\n",
      "[[290.   2.   0.   1.]]\n",
      "[[289.   2.   0.   1.]]\n",
      "[[300.  54.   1.   0.]]\n",
      "[[249.   1.   0.   0.]]\n",
      "[[265.   1.   1.   0.]]\n",
      "[[290.   1.   0.   0.]]\n",
      "[[259.   1.   0.   1.]]\n",
      "[[232.   1.   1.   1.]]\n",
      "[[1. 1. 1. 1.]]\n",
      "[[32.  1.  1.  1.]]\n",
      "[[17.  1.  1.  0.]]\n",
      "[[65.  1.  0.  0.]]\n",
      "[[51.  1.  1.  0.]]\n",
      "[[289.   1.   1.   1.]]\n",
      "[[275.   1.   0.   1.]]\n",
      "[[215.   1.   0.   0.]]\n",
      "[[225.   1.   0.   0.]]\n",
      "[[92.  1.  1.  0.]]\n",
      "[[115.   1.   0.   0.]]\n",
      "[[103.   1.   0.   0.]]\n",
      "[[177.   1.   1.   0.]]\n",
      "[[193.   1.   1.   0.]]\n",
      "[[146.   1.   1.   0.]]\n",
      "[[109.   1.   1.   1.]]\n",
      "[[11.  1.  0.  1.]]\n",
      "[[1. 1. 0. 0.]]\n",
      "[[159.   1.   0.   1.]]\n",
      "[[133.   1.   0.   1.]]\n",
      "[[82.  1.  0.  1.]]\n",
      "[[219.   1.   1.   0.]]\n",
      "[[68.  1.  1.  1.]]\n",
      "[[184.   1.   0.   1.]]\n",
      "[[150.   1.   0.   0.]]\n",
      "[[204.   1.   1.   1.]]\n",
      "[[290.   1.   0.   1.]]\n",
      "[[76.  1.  1.  0.]]\n",
      "[[263.   8.   0.   1.]]\n",
      "[[108. 109.   0.   0.]]\n",
      "[[229. 109.   0.   0.]]\n",
      "[[  1. 109.   1.   1.]]\n",
      "[[300. 109.   0.   1.]]\n",
      "[[ 1. 23.  1.  0.]]\n",
      "[[101.  25.   0.   0.]]\n",
      "[[ 53. 109.   0.   1.]]\n",
      "[[300.  13.   0.   1.]]\n",
      "[[201.  21.   1.   0.]]\n",
      "[[164. 109.   1.   1.]]\n",
      "[[51. 16.  0.  1.]]\n",
      "[[262.  82.   1.   0.]]\n",
      "[[139.  13.   0.   0.]]\n",
      "[[103.  71.   1.   1.]]\n",
      "[[125.   1.   1.   0.]]\n",
      "[[213.  72.   1.   1.]]\n",
      "[[167.   1.   1.   0.]]\n",
      "[[42.  1.  0.  1.]]\n",
      "[[39.  1.  1.  0.]]\n",
      "[[25.  1.  0.  0.]]\n",
      "[[255.   1.   1.   0.]]\n",
      "[[ 1. 75.  1.  1.]]\n",
      "[[214.   1.   1.   1.]]\n",
      "[[121.   1.   0.   1.]]\n",
      "[[240.   1.   0.   1.]]\n",
      "[[172.   1.   0.   1.]]\n",
      "[[59.  1.  1.  1.]]\n",
      "[[7. 1. 1. 0.]]\n",
      "[[144.   1.   0.   1.]]\n",
      "[[196. 109.   1.   0.]]\n",
      "[[152.   1.   1.   1.]]\n",
      "[[188.   1.   1.   1.]]\n",
      "[[54.  1.  0.  1.]]\n",
      "[[98.  1.  1.  1.]]\n",
      "[[237.   1.   1.   0.]]\n",
      "[[34.  1.  0.  0.]]\n",
      "[[275.   1.   1.   0.]]\n",
      "[[300.  79.   1.   1.]]\n",
      "[[209.   1.   1.   0.]]\n",
      "[[270.   1.   0.   0.]]\n",
      "[[247.   1.   1.   1.]]\n",
      "[[93.  1.  0.  1.]]\n",
      "[[196.   1.   0.   1.]]\n",
      "[[20.  1.  0.  1.]]\n",
      "[[265. 109.   1.   0.]]\n",
      "[[138.   1.   0.   0.]]\n",
      "[[165.   1.   1.   1.]]\n",
      "[[73.  1.  0.  1.]]\n",
      "[[137.   1.   1.   1.]]\n",
      "[[136.  82.   1.   1.]]\n",
      "[[47.  1.  1.  1.]]\n",
      "[[202.   1.   0.   0.]]\n",
      "[[270.   1.   1.   1.]]\n",
      "[[87.  1.  1.  1.]]\n",
      "[[243.   1.   1.   0.]]\n",
      "[[208.   1.   0.   1.]]\n",
      "[[118.   1.   1.   0.]]\n",
      "[[86.  1.  0.  0.]]\n",
      "[[188.   1.   0.   0.]]\n",
      "[[232.   1.   0.   0.]]\n",
      "[[107.   1.   1.   0.]]\n",
      "[[4. 1. 0. 1.]]\n",
      "[[132.   1.   1.   0.]]\n",
      "[[75. 87.  0.  0.]]\n",
      "[[15.  1.  0.  0.]]\n",
      "[[70.  1.  1.  0.]]\n",
      "[[158.   1.   1.   0.]]\n",
      "[[29. 91.  1.  1.]]\n",
      "[[172.   1.   1.   1.]]\n",
      "[[37.  1.  1.  1.]]\n",
      "[[221.   1.   0.   1.]]\n",
      "[[58.  1.  0.  0.]]\n",
      "[[63.  1.  1.  0.]]\n",
      "[[180.   1.   1.   1.]]\n",
      "[[253.   1.   0.   1.]]\n",
      "[[280.   1.   0.   0.]]\n",
      "[[47.  1.  0.  0.]]\n",
      "[[184.   1.   1.   0.]]\n",
      "[[97.  1.  0.  0.]]\n",
      "[[226.   1.   1.   1.]]\n",
      "[[25.  1.  1.  1.]]\n",
      "[[128.   1.   0.   1.]]\n",
      "[[82.  1.  1.  0.]]\n",
      "[[163.   1.   0.   0.]]\n",
      "[[115.   1.   1.   1.]]\n",
      "[[280.   1.   1.   1.]]\n",
      "[[29.  1.  0.  1.]]\n",
      "[[199.   1.   1.   0.]]\n",
      "[[265.   1.   0.   1.]]\n",
      "[[229.   1.   1.   0.]]\n",
      "[[14.  1.  1.  1.]]\n",
      "[[126.   1.   0.   0.]]\n",
      "[[142.   1.   0.   0.]]\n",
      "[[62.  1.  0.  1.]]\n",
      "[[245.   1.   0.   1.]]\n",
      "[[78.  1.  1.  1.]]\n",
      "[[261.   1.   1.   1.]]\n",
      "[[9. 1. 0. 0.]]\n",
      "[[261.   1.   0.   0.]]\n",
      "[[206.   1.   0.   0.]]\n",
      "[[170.   1.   0.   0.]]\n",
      "[[199.   1.   1.   1.]]\n",
      "[[190.  53.   0.   0.]]\n",
      "[[177.   1.   0.   1.]]\n",
      "[[285.   1.   1.   0.]]\n",
      "[[180.  11.   1.   1.]]\n",
      "[[136.  54.   0.   0.]]\n",
      "[[104.   1.   1.   1.]]\n",
      "[[78.  1.  0.  0.]]\n",
      "[[44.  1.  1.  0.]]\n",
      "[[112.   1.   1.   0.]]\n",
      "[[235.   1.   0.   1.]]\n",
      "[[284.   1.   0.   1.]]\n",
      "[[254.   1.   1.   1.]]\n",
      "[[55.  1.  1.  0.]]\n",
      "[[229.   1.   0.   1.]]\n",
      "[[162.   1.   1.   0.]]\n",
      "[[240.   1.   0.   0.]]\n",
      "[[146.   1.   0.   0.]]\n",
      "[[138. 107.   1.   0.]]\n",
      "[[180.   1.   0.   0.]]\n",
      "[[107.   1.   0.   1.]]\n",
      "[[89.  1.  0.  1.]]\n",
      "[[154.   1.   0.   1.]]\n",
      "[[174.   1.   0.   0.]]\n",
      "[[116.   1.   0.   1.]]\n",
      "[[125.   1.   0.   1.]]\n",
      "[[29.  1.  1.  0.]]\n",
      "[[284.  68.   1.   0.]]\n",
      "[[239.   1.   1.   1.]]\n",
      "[[148.   1.   1.   1.]]\n",
      "[[143.   1.   1.   1.]]\n",
      "[[288.   1.   0.   0.]]\n",
      "[[127.   1.   1.   1.]]\n",
      "[[37.  1.  0.  1.]]\n",
      "[[218.   1.   1.   1.]]\n",
      "[[2. 1. 1. 0.]]\n",
      "[[110.   1.   0.   0.]]\n",
      "[[22.  1.  1.  0.]]\n",
      "[[68.  1.  0.  0.]]\n",
      "[[4. 1. 1. 1.]]\n",
      "[[15.  1.  0.  1.]]\n",
      "[[84. 50.  0.  1.]]\n",
      "[[242.   1.   1.   1.]]\n",
      "[[290.   2.   1.   0.]]\n",
      "[[168.   1.   0.   1.]]\n",
      "[[11.  1.  1.  0.]]\n",
      "[[130.   1.   0.   0.]]\n",
      "[[ 82. 109.   1.   0.]]\n",
      "[[211.   1.   0.   0.]]\n",
      "[[51.  1.  0.  1.]]\n",
      "[[73.  1.  1.  1.]]\n",
      "[[21.  1.  1.  1.]]\n",
      "[[8. 1. 0. 1.]]\n",
      "[[191.   1.   0.   1.]]\n",
      "[[96.  1.  1.  1.]]\n",
      "[[101.   1.   1.   0.]]\n",
      "[[270.   1.   1.   0.]]\n",
      "[[266.   1.   1.   1.]]\n",
      "[[257.   1.   1.   1.]]\n",
      "[[233.  87.   1.   0.]]\n",
      "[[203.   1.   1.   0.]]\n",
      "[[223.   1.   1.   1.]]\n",
      "[[250.   1.   0.   1.]]\n",
      "[[42.  1.  0.  0.]]\n",
      "[[156.   1.   1.   1.]]\n",
      "[[214.   1.   1.   0.]]\n",
      "[[89.  1.  1.  0.]]\n",
      "[[175.   1.   1.   1.]]\n",
      "[[139.   1.   1.   0.]]\n",
      "[[153.   1.   1.   0.]]\n",
      "[[140.   1.   0.   1.]]\n",
      "[[73.  1.  0.  0.]]\n",
      "[[197.   1.   0.   0.]]\n",
      "[[196.   1.   1.   1.]]\n",
      "[[171.   1.   1.   0.]]\n",
      "[[ 24. 109.   1.   0.]]\n",
      "[[258.   1.   1.   0.]]\n",
      "[[42.  1.  1.  1.]]\n",
      "[[196.  87.   1.   0.]]\n",
      "[[45.  1.  0.  1.]]\n",
      "[[119.   1.   1.   1.]]\n",
      "[[32.  1.  0.  0.]]\n",
      "[[250.   1.   1.   0.]]\n",
      "[[20.  3.  0.  1.]]\n",
      "[[ 1. 48.  1.  0.]]\n",
      "[[78. 14.  1.  0.]]\n",
      "[[90.  1.  1.  1.]]\n",
      "[[161.   1.   1.   1.]]\n",
      "[[157.   1.   0.   0.]]\n",
      "[[280.  92.   0.   0.]]\n",
      "[[101.   1.   0.   1.]]\n",
      "[[217.   1.   0.   1.]]\n",
      "[[92.  1.  0.  0.]]\n",
      "[[ 6. 90.  0.  0.]]\n",
      "[[225.   1.   1.   0.]]\n",
      "[[54.  1.  1.  1.]]\n",
      "[[25.  1.  0.  1.]]\n",
      "[[186.   1.   0.   1.]]\n",
      "[[83.  1.  1.  1.]]\n",
      "[[277.   1.   1.   1.]]\n",
      "[[53.  1.  0.  0.]]\n",
      "[[133.   1.   1.   1.]]\n",
      "[[118.   1.   0.   0.]]\n",
      "[[273.   1.   0.   0.]]\n",
      "[[279.   1.   1.   0.]]\n",
      "[[58.  1.  0.  1.]]\n",
      "[[66.  1.  0.  1.]]\n",
      "[[254.   1.   0.   0.]]\n",
      "[[184.   1.   1.   1.]]\n",
      "[[219.  49.   0.   0.]]\n",
      "[[6. 1. 0. 0.]]\n",
      "[[286.   1.   1.   1.]]\n",
      "[[112.   1.   0.   1.]]\n",
      "[[64.  1.  1.  1.]]\n",
      "[[21.  1.  0.  0.]]\n",
      "[[33.  1.  1.  0.]]\n",
      "[[204.   1.   0.   1.]]\n",
      "[[235.   1.   1.   1.]]\n",
      "[[283.   1.   1.   0.]]\n",
      "[[110.  45.   1.   1.]]\n",
      "[[236.   1.   0.   0.]]\n",
      "[[154.  96.   0.   0.]]\n",
      "[[288.   4.   1.   1.]]\n",
      "[[300.  73.   0.   0.]]\n",
      "[[229.  16.   0.   0.]]\n",
      "[[246.  58.   0.   1.]]\n",
      "[[113.   9.   1.   1.]]\n",
      "[[300.   4.   0.   0.]]\n",
      "[[51. 82.  0.  0.]]\n",
      "[[39. 42.  0.  1.]]\n",
      "[[154.  62.   1.   0.]]\n",
      "[[115.  89.   0.   0.]]\n",
      "[[211.   6.   0.   1.]]\n",
      "[[241.  35.   0.   0.]]\n",
      "[[198.  37.   1.   0.]]\n",
      "[[63. 39.  0.  0.]]\n",
      "[[266.  56.   0.   0.]]\n",
      "[[177.  94.   1.   0.]]\n",
      "[[289.   1.   1.   0.]]\n",
      "[[158.   8.   1.   0.]]\n",
      "[[247. 109.   1.   1.]]\n",
      "[[76. 68.  1.  0.]]\n",
      "[[94. 91.  1.  1.]]\n",
      "[[243.   7.   1.   0.]]\n",
      "[[214.  96.   1.   1.]]\n",
      "[[122.  66.   0.   1.]]\n",
      "[[222.  33.   1.   1.]]\n",
      "[[173.  52.   1.   1.]]\n",
      "[[131.  36.   0.   1.]]\n",
      "[[19. 41.  0.  1.]]\n",
      "[[190.  70.   1.   0.]]\n",
      "[[300.  36.   0.   1.]]\n",
      "[[280. 109.   1.   1.]]\n",
      "[[235.  68.   0.   0.]]\n",
      "[[290.   1.   0.   1.]]\n",
      "[[62.  5.  0.  0.]]\n",
      "[[92.  7.  1.  1.]]\n",
      "[[84. 33.  1.  0.]]\n",
      "[[39. 25.  1.  0.]]\n",
      "[[18. 76.  0.  1.]]\n",
      "[[194.   1.   0.   0.]]\n",
      "[[123. 109.   1.   1.]]\n",
      "[[181.  34.   0.   1.]]\n",
      "[[122.   1.   1.   0.]]\n",
      "[[76.  1.  0.  1.]]\n",
      "[[290.   2.   0.   0.]]\n",
      "[[96.  1.  1.  0.]]\n",
      "[[39. 73.  1.  1.]]\n",
      "[[70.  1.  0.  1.]]\n",
      "[[282.  49.   0.   1.]]\n",
      "[[1. 6. 1. 0.]]\n",
      "[[278.   1.   0.   1.]]\n",
      "[[1. 4. 0. 0.]]\n",
      "[[ 1. 12.  1.  0.]]\n",
      "[[262.  38.   1.   1.]]\n",
      "[[291.   2.   1.   0.]]\n",
      "[[ 1. 34.  1.  1.]]\n",
      "[[40.  7.  1.  1.]]\n",
      "[[154.  79.   1.   1.]]\n",
      "[[249.  92.   0.   0.]]\n",
      "[[180. 109.   1.   0.]]\n",
      "[[ 68. 109.   0.   1.]]\n",
      "[[288.   1.   0.   1.]]\n",
      "[[ 38. 109.   0.   0.]]\n",
      "[[ 9. 61.  1.  1.]]\n",
      "[[212. 109.   1.   1.]]\n",
      "[[300.  94.   1.   0.]]\n",
      "[[52. 30.  0.  0.]]\n",
      "[[205.  57.   1.   1.]]\n",
      "[[211.   1.   1.   1.]]\n",
      "[[98. 56.  0.  0.]]\n",
      "[[250.  73.   1.   1.]]\n",
      "[[117.  30.   1.   1.]]\n",
      "[[277.   1.   0.   0.]]\n",
      "[[129.   5.   1.   1.]]\n",
      "[[146.  31.   0.   0.]]\n",
      "[[193.   5.   0.   0.]]\n",
      "[[6. 1. 1. 1.]]\n",
      "[[267.   1.   0.   0.]]\n",
      "[[135.   1.   1.   0.]]\n",
      "[[234.  49.   1.   1.]]\n",
      "[[60. 94.  1.  1.]]\n",
      "[[37.  1.  0.  0.]]\n",
      "[[213.   1.   0.   1.]]\n",
      "[[88. 76.  0.  1.]]\n",
      "[[163.   1.   0.   1.]]\n",
      "[[63. 74.  0.  1.]]\n",
      "[[97. 39.  1.  0.]]\n",
      "[[284.   1.   1.   1.]]\n",
      "[[224.   1.   0.   1.]]\n",
      "[[169.   1.   1.   1.]]\n",
      "[[69. 53.  1.  0.]]\n",
      "[[222.   1.   0.   0.]]\n",
      "[[1. 7. 1. 1.]]\n",
      "[[19. 27.  1.  0.]]\n",
      "[[279.  34.   0.   0.]]\n",
      "[[270.  71.   0.   1.]]\n",
      "[[139.  68.   0.   0.]]\n",
      "[[ 95. 109.   1.   0.]]\n",
      "[[122.  51.   1.   0.]]\n",
      "[[151. 109.   1.   0.]]\n",
      "[[168.  26.   0.   0.]]\n",
      "[[130.  95.   0.   0.]]\n",
      "[[70. 27.  0.  1.]]\n",
      "[[44. 94.  1.  1.]]\n",
      "[[219.   1.   1.   0.]]\n",
      "[[1. 1. 1. 0.]]\n",
      "[[81.  1.  1.  0.]]\n",
      "[[52.  1.  1.  1.]]\n",
      "[[4. 1. 1. 0.]]\n",
      "[[70.  1.  1.  1.]]\n",
      "[[4. 1. 1. 0.]]\n",
      "[[290.   1.   0.   0.]]\n",
      "[[147.  46.   1.   1.]]\n",
      "[[41. 57.  0.  1.]]\n",
      "[[149.   1.   1.   0.]]\n",
      "[[256.   1.   0.   1.]]\n",
      "[[209.  31.   0.   1.]]\n",
      "[[207.   1.   1.   1.]]\n",
      "[[187.   1.   1.   0.]]\n",
      "[[160.   1.   0.   0.]]\n",
      "[[123.   1.   0.   0.]]\n",
      "[[251.  46.   0.   0.]]\n",
      "[[136.   1.   0.   1.]]\n",
      "[[265.  95.   1.   1.]]\n",
      "[[18.  1.  0.  0.]]\n",
      "[[220.  83.   0.   0.]]\n",
      "[[28.  1.  1.  1.]]\n",
      "[[234.   1.   1.   0.]]\n",
      "[[223.  62.   1.   1.]]\n",
      "[[182.  81.   0.   1.]]\n",
      "[[130.   1.   1.   1.]]\n",
      "[[ 14. 101.   0.   1.]]\n",
      "[[185.   1.   0.   0.]]\n",
      "[[48.  1.  0.  1.]]\n",
      "[[165.  87.   1.   0.]]\n",
      "[[149.   1.   0.   1.]]\n",
      "[[285.  81.   0.   1.]]\n",
      "[[181.   1.   1.   0.]]\n",
      "[[190.   1.   1.   0.]]\n",
      "[[100.   1.   0.   0.]]\n",
      "[[121.  78.   1.   1.]]\n",
      "[[273.   1.   1.   1.]]\n",
      "[[85.  1.  0.  1.]]\n",
      "[[193.   1.   1.   1.]]\n",
      "[[174.   1.   1.   0.]]\n",
      "[[178.   1.   1.   1.]]\n",
      "[[201.   1.   1.   1.]]\n",
      "[[39.  1.  0.  1.]]\n",
      "[[246.   1.   0.   0.]]\n",
      "[[101.   1.   1.   1.]]\n",
      "[[10.  1.  1.  1.]]\n",
      "[[228.   1.   0.   0.]]\n",
      "[[264.   1.   0.   0.]]\n",
      "[[257.   1.   0.   0.]]\n",
      "[[23.  1.  0.  1.]]\n",
      "[[131.   1.   0.   1.]]\n",
      "[[61.  1.  1.  1.]]\n",
      "[[123.   1.   1.   1.]]\n",
      "[[66.  1.  1.  0.]]\n",
      "[[112.   1.   1.   1.]]\n",
      "[[202.  76.   0.   1.]]\n",
      "[[243.   1.   0.   0.]]\n",
      "[[218.   1.   0.   0.]]\n",
      "[[285.   1.   0.   0.]]\n",
      "[[134.   1.   0.   0.]]\n",
      "[[18.  1.  1.  1.]]\n",
      "[[181.   1.   0.   1.]]\n",
      "[[182.   1.   0.   0.]]\n",
      "[[33.  1.  0.  1.]]\n",
      "[[262.   1.   1.   0.]]\n",
      "[[216.   1.   1.   0.]]\n",
      "[[196.   1.   1.   0.]]\n",
      "[[52. 46.  1.  1.]]\n",
      "[[85.  1.  1.  0.]]\n",
      "[[179.  63.   0.   0.]]\n",
      "[[48.  1.  1.  0.]]\n",
      "[[200.   1.   0.   1.]]\n",
      "[[128.   1.   1.   0.]]\n",
      "[[111.  60.   1.   1.]]\n",
      "[[ 1. 63.  0.  0.]]\n",
      "[[96.  1.  0.  1.]]\n",
      "[[3. 1. 0. 0.]]\n",
      "[[252.   1.   1.   0.]]\n",
      "[[61.  1.  0.  0.]]\n",
      "[[237.  99.   0.   1.]]\n",
      "[[262.   1.   0.   1.]]\n",
      "[[165.   1.   1.   0.]]\n",
      "[[231.   1.   1.   0.]]\n",
      "[[83.  1.  0.  0.]]\n",
      "[[264.   1.   1.   1.]]\n",
      "[[246.   1.   1.   0.]]\n",
      "[[19.  1.  1.  0.]]\n",
      "[[28.  1.  0.  0.]]\n",
      "[[251.   1.   1.   1.]]\n",
      "[[28. 49.  1.  1.]]\n",
      "[[104.   1.   0.   1.]]\n",
      "[[106.   1.   0.   0.]]\n",
      "[[29. 34.  1.  0.]]\n",
      "[[44.  1.  0.  0.]]\n",
      "[[272.  44.   0.   0.]]\n",
      "[[81. 97.  1.  1.]]\n",
      "[[251.   1.   0.   0.]]\n",
      "[[190.  98.   0.   1.]]\n",
      "[[26.  1.  1.  0.]]\n",
      "[[143.   1.   1.   0.]]\n",
      "[[190.  26.   1.   0.]]\n",
      "[[153.   1.   0.   0.]]\n",
      "[[166.   1.   0.   0.]]\n",
      "[[94.  1.  0.  0.]]\n",
      "[[238.   1.   0.   1.]]\n",
      "[[59.  1.  1.  0.]]\n",
      "[[206.   1.   1.   0.]]\n",
      "[[247.   1.   0.   1.]]\n",
      "[[75.  1.  1.  1.]]\n",
      "[[88. 63.  0.  1.]]\n",
      "[[191.   1.   0.   0.]]\n",
      "[[269.   1.   0.   1.]]\n",
      "[[140.   1.   1.   1.]]\n",
      "[[44.  1.  1.  1.]]\n",
      "[[105.  98.   1.   1.]]\n",
      "[[10. 33.  1.  0.]]\n",
      "[[212.   1.   1.   0.]]\n",
      "[[79.  1.  0.  1.]]\n",
      "[[108.   1.   0.   0.]]\n",
      "[[151.   1.   0.   1.]]\n",
      "[[36.  1.  1.  0.]]\n",
      "[[254.  27.   0.   0.]]\n",
      "[[ 1. 98.  1.  0.]]\n",
      "[[3. 6. 1. 0.]]\n",
      "[[227.   4.   1.   1.]]\n",
      "[[234.  25.   0.   1.]]\n",
      "[[104.  83.   0.   0.]]\n",
      "[[116.   1.   1.   0.]]\n",
      "[[143.  93.   1.   1.]]\n",
      "[[230.   1.   0.   0.]]\n",
      "[[272.   1.   0.   1.]]\n",
      "[[258.  64.   1.   0.]]\n",
      "[[290.  41.   0.   0.]]\n",
      "[[158.   1.   1.   1.]]\n",
      "[[50.  1.  1.  1.]]\n",
      "[[300.  25.   1.   0.]]\n",
      "[[161.  53.   0.   0.]]\n",
      "[[241.   1.   1.   0.]]\n",
      "[[171.   4.   0.   0.]]\n",
      "[[146.   4.   0.   1.]]\n",
      "[[134.  24.   1.   0.]]\n",
      "[[290. 101.   0.   0.]]\n",
      "[[268.   1.   1.   0.]]\n",
      "[[203.  98.   0.   0.]]\n",
      "[[75. 40.  1.  1.]]\n",
      "[[232.   1.   0.   1.]]\n",
      "[[155.   1.   1.   0.]]\n",
      "[[145.   1.   1.   1.]]\n",
      "[[13.  1.  0.  0.]]\n",
      "[[14.  1.  1.  0.]]\n",
      "[[30. 80.  0.  0.]]\n",
      "[[110.   1.   0.   1.]]\n",
      "[[219.  23.   1.   0.]]\n",
      "[[16.  1.  1.  1.]]\n",
      "[[174.   1.   0.   1.]]\n",
      "[[155.  24.   1.   1.]]\n",
      "[[147.   1.   0.   1.]]\n",
      "[[177.   1.   0.   0.]]\n",
      "[[207.  45.   0.   0.]]\n",
      "[[16. 52.  0.  0.]]\n",
      "[[151.   1.   1.   0.]]\n",
      "[[204.   1.   0.   0.]]\n",
      "[[225.  97.   0.   0.]]\n",
      "[[ 11. 109.   1.   0.]]\n",
      "[[222.   1.   1.   0.]]\n",
      "[[99.  1.  0.  1.]]\n",
      "[[168.   1.   0.   0.]]\n",
      "[[73.  1.  1.  0.]]\n",
      "[[193.   1.   0.   1.]]\n",
      "[[191.   1.   1.   1.]]\n",
      "[[57.  1.  1.  1.]]\n",
      "[[35.  1.  1.  1.]]\n",
      "[[206.   1.   0.   1.]]\n",
      "[[186.   1.   1.   1.]]\n",
      "[[155.   1.   0.   0.]]\n",
      "[[291.  60.   0.   1.]]\n",
      "[[104.   1.   1.   0.]]\n",
      "[[189.   1.   0.   1.]]\n",
      "[[18. 88.  1.  0.]]\n",
      "[[89.  1.  0.  0.]]\n",
      "[[160.   1.   1.   0.]]\n",
      "[[171.  40.   0.   0.]]\n",
      "[[220.   1.   1.   1.]]\n",
      "[[29. 18.  1.  0.]]\n",
      "[[239.   1.   1.   0.]]\n",
      "[[17.  1.  0.  1.]]\n",
      "[[51. 70.  0.  1.]]\n",
      "[[107.  34.   0.   1.]]\n",
      "[[230.   1.   1.   1.]]\n",
      "[[165.   1.   0.   1.]]\n",
      "[[41.  1.  1.  0.]]\n",
      "[[71.  1.  0.  0.]]\n",
      "[[245.   1.   1.   1.]]\n",
      "[[120.   1.   0.   0.]]\n",
      "[[56.  1.  0.  0.]]\n",
      "[[274.  82.   1.   0.]]\n",
      "[[87.  1.  0.  1.]]\n",
      "[[267.  28.   0.   0.]]\n",
      "[[93.  1.  1.  1.]]\n",
      "[[113.   1.   0.   0.]]\n",
      "[[142.   1.   0.   1.]]\n",
      "[[227.  75.   0.   1.]]\n",
      "[[255. 102.   1.   1.]]\n",
      "[[210.   1.   0.   1.]]\n",
      "[[86. 23.  0.  1.]]\n",
      "[[114.   1.   1.   0.]]\n",
      "[[161.   1.   0.   1.]]\n",
      "[[11.  1.  0.  0.]]\n",
      "[[242.  80.   0.   0.]]\n",
      "[[80.  1.  1.  1.]]\n",
      "[[1. 1. 0. 1.]]\n",
      "[[282.   1.   0.   0.]]\n",
      "[[167.  99.   0.   1.]]\n",
      "[[81.  1.  0.  0.]]\n",
      "[[166.  63.   1.   1.]]\n",
      "[[2. 1. 0. 1.]]\n",
      "[[209.   1.   1.   1.]]\n",
      "[[118. 100.   1.   0.]]\n",
      "[[28.  4.  1.  0.]]\n",
      "[[ 9. 71.  1.  0.]]\n",
      "[[201.   1.   1.   0.]]\n",
      "[[120.  39.   0.   0.]]\n",
      "[[ 91. 100.   0.   0.]]\n",
      "[[30.  1.  0.  0.]]\n",
      "[[66. 63.  0.  1.]]\n",
      "[[144.   1.   0.   0.]]\n",
      "[[70. 99.  0.  0.]]\n",
      "[[260.   1.   1.   0.]]\n",
      "[[292.  88.   1.   0.]]\n",
      "[[121.   1.   1.   1.]]\n",
      "[[79.  1.  1.  0.]]\n",
      "[[40.  1.  0.  0.]]\n",
      "[[157.   1.   0.   1.]]\n",
      "[[202.  65.   0.   0.]]\n",
      "[[ 31. 100.   0.   0.]]\n",
      "[[ 1. 32.  1.  0.]]\n",
      "[[130.   1.   1.   0.]]\n",
      "[[135.   1.   1.   1.]]\n",
      "[[242.   1.   0.   1.]]\n",
      "[[179.   1.   0.   1.]]\n",
      "[[167.   1.   1.   1.]]\n",
      "[[60.  1.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "## define the domain of the considered parameters\n",
    "n_estimators = tuple(np.arange(1,301,1, dtype= np.int))\n",
    "# print(n_estimators)\n",
    "max_depth = tuple(np.arange(1,110,1, dtype= np.int))\n",
    "# max_features = ('log2', 'sqrt', None)\n",
    "max_features = (0, 1)\n",
    "# criterion = ('gini', 'entropy')\n",
    "criterion = (0, 1)\n",
    "\n",
    "\n",
    "# define the dictionary for GPyOpt\n",
    "domain = [{'n_estimators': 'var_1',  'type': 'discrete',     'domain': n_estimators},\n",
    "          {'max_depth': 'var_2',     'type': 'discrete',     'domain': max_depth},\n",
    "          {'max_features': 'var_3',  'type': 'categorical',  'domain': max_features},\n",
    "          {'criterion': 'var_4',     'type': 'categorical',  'domain': criterion}]\n",
    "\n",
    "\n",
    "## we have to define the function we want to maximize --> validation accuracy, \n",
    "## note it should take a 2D ndarray but it is ok that it assumes only one point\n",
    "## in this setting\n",
    "def objective_function(x): \n",
    "    print(x)\n",
    "    # we have to handle the categorical variables that is convert 0/1 to labels\n",
    "    # log2/sqrt and gini/entropy\n",
    "    \n",
    "    param = x[0]\n",
    "    \n",
    "    if param[2] == 0:\n",
    "        var_3 = \"log2\"\n",
    "    else:\n",
    "        var_3 = \"sqrt\"\n",
    "    \n",
    "    if param[3] == 0:\n",
    "        var_4 = \"gini\"\n",
    "    else:\n",
    "        var_4 = \"entropy\"\n",
    "        \n",
    "        \n",
    "#fit the model\n",
    "    model = RandomForestClassifier(n_estimators = int(param[0]), criterion = var_4, max_depth = int(param[1]), max_features = var_3)\n",
    "    model.fit(Xcattrain, ytrain)\n",
    "    forestPreds = model.predict(Xcattest)\n",
    "    accuracy = len(forestPreds[torch.tensor(forestPreds, dtype = torch.int64) == ytest]) / len(forestPreds)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "opt = GPyOpt.methods.BayesianOptimization(f = objective_function,   # function to optimize\n",
    "                                              domain = domain,         # box-constrains of the problem\n",
    "                                              acquisition_type = \"EI\",      # Select acquisition function MPI, EI, LCB\n",
    "                                             )\n",
    "opt.acquisition.exploration_weight=.1\n",
    "\n",
    "opt.run_optimization(max_iter = 100) \n",
    "\n",
    "\n",
    "x_best = opt.X[np.argmin(opt.Y)]\n",
    "print(\"The best parameters obtained: n_estimators=\" + str(x_best[0]) + \", max_depth=\" + str(x_best[1]) + \", max_features=\" + str(\n",
    "    x_best[2])  + \", criterion=\" + str(\n",
    "    x_best[3]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
